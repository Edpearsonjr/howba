library('Hmisc')
library('corrplot')
library('ggplot2')
library('cluster')
library('LICORS')
library('fpc')
basketballDb <- dbConnect(SQLite(), "/Users/abhinav/Abhinav/howba/app/src/gp1/db/basketBall.db")
# lets look at the SG- Shooting Guard position
# Main objective is to score points
# They need to have long range shots - 3P should be high
# They may also assist well
# SG-SF are known as wingman
# Good free throw percentage too
# SG-PG has value too
# Some of the features to consider for Shooting Guard position conisdering the charactersitcs
# Percentage of games started(Indication of a good player)
# Mintutes played(Generally indicates a good player)
# 3P
# 3PA
# 2P
# 2PA
# FT
# FTA
# AST
# STL
# PTS
# TOV
# If he played the dual role like SG-SF SG-PG SG-PF
# if he was the MVP of the season
# the experience that he has (sometimes if he is too aged it might play a role in deciding whether to hire or no)
#---------------------------------------------------------------------------------------------------------------
#Trying for the 2012-2013 season only now
sqlStatement  <- "SELECT * FROM SG_PREVIOUS5YEARS_AVERAGE"
playerTotals <- dbGetQuery(basketballDb, sqlStatement)
shootingGuardsPrevious5years <- tbl_df(playerTotals)
# select a few columns and prepare the data for cluster analysis
# if the player has played shooting-guard and smallforward he is given a value of 1 in a separate column
# likewise do it for sg-pf, sg-pg
shootingGuards <- shootingGuardsPrevious5years %>%
select(GAMES, GAMES_STARTED, MINUTES_PLAYED, FIELD_GOALS, FIELD_GOALS_ATTEMPTS, TWO_POINTS_FG, TWO_POINTS_FG_ATTEMPTS,
THREE_POINTS_FG, THREE_POINTS_FG_ATTEMPTS, EFF_FIELD_GOAL_PERCENT, FREE_THROWS, FREE_THROWS_ATTEMPTS,
ASSISTS, TURNOVERS, POINTS)
zscores <- tbl_df(data.frame(scale(shootingGuards, center=TRUE, scale=TRUE))) %>%
mutate(PLAYER_ID=shootingGuardsPrevious5years$PLAYER_ID)
# in order to decide which variables to keep and which not to
# here we perform co-relational analysis using the Hmisc library
flatternCorrelationMatrix <- function(cormat, pmat) {
ut <- upper.tri(cormat)
data.frame(
row = rownames(cormat)[row(cormat)[ut]],
col = rownames(cormat)[col(cormat)[ut]],
cor = (cormat)[ut],
p = pmat[ut]
)
}
correlation <- rcorr(as.matrix(shootingGuards))
correlationFlattened = flatternCorrelationMatrix(correlation$r, correlation$P)
corGreaterThan99 <- filter(correlationFlattened, cor>0.95)
print(corGreaterThan99)
corrplot(correlation$r, type="upper", order="hclust", tl.col="black", tl.srt=45)
#some of the variables that were identified to remove are as follows
# FG_Attempted
# Field_Goals
# 3PFGA
# FTA
# 2PFGA
features <- shootingGuardsPrevious5years %>%
select(-c(PLAYER_ID,FIELD_GOALS, FIELD_GOALS_ATTEMPTS, THREE_POINTS_FG_ATTEMPTS, FREE_THROWS_ATTEMPTS, TWO_POINTS_FG_ATTEMPTS)) %>%
mutate(
GAMES = (GAMES - mean(GAMES))/sd(GAMES),
GAMES_STARTED = (GAMES_STARTED - mean(GAMES_STARTED))/sd(GAMES_STARTED),
MINUTES_PLAYED= (MINUTES_PLAYED - mean(MINUTES_PLAYED)) / sd(MINUTES_PLAYED),
THREE_POINTS_FG = (THREE_POINTS_FG - mean(THREE_POINTS_FG)) / sd(THREE_POINTS_FG),
FREE_THROWS = (FREE_THROWS - mean(FREE_THROWS)) / sd(FREE_THROWS),
TWO_POINTS_FG = (TWO_POINTS_FG - mean(TWO_POINTS_FG)) / sd(TWO_POINTS_FG),
ASSISTS = (ASSISTS - mean(ASSISTS)) / sd(ASSISTS),
TURNOVERS = (TURNOVERS - mean(TURNOVERS)) / sd(TURNOVERS),
POINTS = (POINTS - mean(POINTS)) / sd(POINTS)
) %>%
select(-c(SALARY))
withinGroupSumSquares <- numeric(0)
betweenGroupSumSquares <- numeric(0)
range <- 1:20
for(i in range){
km <- kmeans(features, i, iter.max=100, nstart=10)
sumSquares <- km$tot.withinss
betweenSquares <- km$betweenss
withinGroupSumSquares <- c(withinGroupSumSquares, sumSquares)
betweenGroupSumSquares <- c(betweenGroupSumSquares, betweenSquares)
}
plotFrame <- data.frame(numClusters=range, sumOfSquares=withinGroupSumSquares, betweenGroupSumSquares=betweenGroupSumSquares)
ggplot(plotFrame, aes(x=numClusters, y=sumOfSquares)) +
geom_point() +
geom_line()
print(plotFrame)
# This is determined from the elbow graph
finalNumberOfClusters = 3
membersOfClusters <- list()
km <- kmeanspp(features, k=finalNumberOfClusters, start="random", iter.max = 100, nstart = 45)
clusters <- km$cluster
centers = km$centers
size <- km$size
withinGroupSumSquares <- km$tot.withinss
betweenGroupSumSquares <- km$betweenss
kmeans <- kmeansruns(features, krange=2:10)
bestNumberOfClusters <- kmeans$bestk
centersFpc <- kmeans$centers
withinGroupSumSquaresFpc <- kmeans$tot.withinss
betweenGroupSumSquaresFpc <- kmeans$betweenss
comparison <- data.frame(withinSumOfSquares = c(withinGroupSumSquares, withinGroupSumSquaresFpc),
betweenGroupSumSquares = c(betweenGroupSumSquares, betweenGroupSumSquaresFpc))
print(comparison)
#The conclusion here is using the two packages are same
# The difference is fpc gives the best number of clusters using the silhouette method
# We have calculated using the elbow method
# however we chose the elbow graph method because number of cluster being 3 achieved better
# between group sum of squares being large means better in terms of making a judgement
membersOfClusters <- list()
km <- kmeanspp(features, k=finalNumberOfClusters, start="random", iter.max = 100, nstart = 45)
clusters <- km$cluster
for(i in 1:finalNumberOfClusters){
members_i <- shootingGuardsPrevious5years[which(clusters == i),]
membersOfClusters[[i]] <- members_i
}
ncols <- ncol(membersOfClusters[[1]])
mean_matrix <- matrix(nrow=finalNumberOfClusters, ncol=ncols)
dimension_names <- dimnames(membersOfClusters[[1]])
for(i in 1:finalNumberOfClusters){
mean_matrix[i, ] <- sapply(membersOfClusters[[i]], mean)
}
colnames(mean_matrix) <- dimension_names[[2]]
mean_matrix <- mean_matrix[,2:ncols]
print(mean_matrix)
#consider points variable - since shooting guard needs to score more and should have a better three point game
mean_points <- mean(shootingGuardsPrevious5years$POINTS)
sd_points <- sd(shootingGuardsPrevious5years$POINTS)
score_90Percentile <- round(qnorm(0.9, mean=mean_points, sd=sd_points), digits=0)
totalAbove90Percentile <- sum(shootingGuardsPrevious5years$POINTS > score_90Percentile)
above90Percentile <- numeric(0)
for(i in 1:finalNumberOfClusters){
numberOfPlayersIn90Percentile <- sum(membersOfClusters[[i]]$POINTS > score_90Percentile) / totalAbove90Percentile
above90Percentile <- c(above90Percentile, numberOfPlayersIn90Percentile * 100)
}
print(above90Percentile)
mean_assists <- mean(shootingGuardsPrevious5years$ASSISTS)
sd_assists <- sd(shootingGuardsPrevious5years$ASSIST)
assists_90Percentile <- round(qnorm(0.9, mean=mean_assists, sd=sd_assists), digits=0)
totalAssistsAbove90Percentile <- sum(shootingGuardsPrevious5years$ASSISTS > assists_90Percentile)
assistsaAbove90Percentile <- numeric(0)
for(i in 1:finalNumberOfClusters){
numberOfPlayersIn90Percentile <- sum(membersOfClusters[[i]]$ASSISTS > assists_90Percentile) / totalAssistsAbove90Percentile
assistsaAbove90Percentile <- c(assistsaAbove90Percentile, numberOfPlayersIn90Percentile * 100)
}
print(assistsaAbove90Percentile)
mean_three_pointers <- mean(shootingGuardsPrevious5years$THREE_POINTS_FG)
sd_three_pointers <- sd(shootingGuardsPrevious5years$THREE_POINTS_FG)
threepointers_90Percentile <- round(qnorm(0.9, mean=mean_three_pointers, sd=sd_three_pointers), digits=0)
totalThreePointersAbove90Percentile <- sum(shootingGuardsPrevious5years$THREE_POINTS_FG > threepointers_90Percentile)
threepointersAbove90Percentile <- numeric(0)
for(i in 1:finalNumberOfClusters){
numberOfPlayersIn90Percentile <- sum(membersOfClusters[[i]]$THREE_POINTS_FG > threepointers_90Percentile) / totalThreePointersAbove90Percentile
threepointersAbove90Percentile <- c(threepointersAbove90Percentile, numberOfPlayersIn90Percentile * 100)
}
bestPlayerspercentagesInEachCluster <- data.frame(points = above90Percentile, assists=assistsaAbove90Percentile, threepointers=threepointersAbove90Percentile)
print(bestPlayerspercentagesInEachCluster)
#This clearly justifies the high quality of the players in the clusters
# The best cluster has 100%  of the top 10% good shooters
# The best cluster has 77.77% if the top 10% good passers
# The number of best three pointers are shared between two of them
# now look at the best cluster
# calcluate the mean and the stanadard deviation of the salaries in that cluster
# select someone who is a good shooter but is being paid less
# This will be a good pick for the boss
# player with id 2898 has top 10% skills in points scoring and is in top 10% in assists
# he is paid around 3 million less than the mean of salaries in that cluster
bestCluster <- which.max(bestPlayerspercentagesInEachCluster$points)
meanSalaryBestCluster <- mean(membersOfClusters[[bestCluster]]$SALARY)
makeAnOffer <- tbl_df(membersOfClusters[[bestCluster]]) %>%
filter(ASSISTS > assists_90Percentile, POINTS > score_90Percentile, SALARY < meanSalaryBestCluster)
print(makeAnOffer)
mean(shootingGuardsPrevious5years$SALARY)
library('RSQLite') # Loads the pacakges that is reqiured for reading from the sql database
library('dplyr') # perform operations on data frame
library('Hmisc')
library('corrplot')
library('ggplot2')
library('cluster')
library('LICORS')
library('fpc')
source('utils.R')
basketballDb <- dbConnect(SQLite(), "/Users/abhinav/Abhinav/howba/app/src/gp1/db/basketBall.db")
sqlStatement  <- "SELECT * FROM C_PREVIOUS5YEARS"
playerStats <- dbGetQuery(basketballDb, sqlStatement)
playerStats <- tbl_df(playerStats)
playerStats <- playerStats %>%
group_by(PLAYER_ID) %>%
summarise(GAMES= mean(GAMES),
GAMES_STARTED=mean(GAMES_STARTED),
MINUTES_PLAYED = mean(MINUTES_PLAYED),
TWO_POINTS_FG = mean(TWO_POINTS_FG),
TWO_POINTS_FG_ATTEMPTS= mean(TWO_POINTS_FG_ATTEMPTS),
EFF_FIELD_GOAL_PERCENT = mean(EFF_FIELD_GOAL_PERCENT),
OFFENSIVE_REBOUNDS = mean(OFFESNIVE_REBOUNDS),
DEFENSIVE_REBOUNDS = mean(DEFENSIVE_REBOUNDS),
BLOCKS = mean(BLOCKS),
POINTS=mean(POINTS),
SALARY=mean(SALARY),
POSITION=paste(POSITION, collapse=",")) %>%
mutate(c_sg= ifelse(grepl("C-SG",POSITION, fixed=TRUE), 1, ifelse(grepl("SG", POSITION, fixed=TRUE), 1, 0))) %>%
mutate(c_sf=ifelse(grepl("C-SF",POSITION, fixed=TRUE), 1 , ifelse(grepl("SF", POSITION, fixed=TRUE), 1, 0)))%>%
mutate(c_pg=ifelse(grepl("C-PG",POSITION, fixed=TRUE), 1 , ifelse(grepl("PG", POSITION, fixed=TRUE), 1, 0)))%>%
mutate(c_pf=ifelse(grepl("C-PF",POSITION, fixed=TRUE), 1 , ifelse(grepl("PF", POSITION, fixed=TRUE), 1, 0))) %>%
select(-c(POSITION))
cAttributes <- playerStats %>%
select(-c(PLAYER_ID, c_sg, c_sf, c_pg, c_pf))
# among the attributes that are selected find the correlations between then
correlation <- rcorr(as.matrix(cAttributes))
View(correlation$r)
library('RSQLite') # Loads the pacakges that is reqiured for reading from the sql database
library('usdm')
library('dplyr') # perform operations on data frame
library('Hmisc')
library('corrplot')
library('ggplot2')
library('cluster')
library('LICORS')
library('fpc')
source('utils.R')
basketballDb <- dbConnect(SQLite(), "/Users/abhinav/Abhinav/howba/app/src/gp1/db/basketBall.db")
sqlStatement  <- "SELECT * FROM C_PREVIOUS5YEARS"
playerStats <- dbGetQuery(basketballDb, sqlStatement)
playerStats <- tbl_df(playerStats)
playerStats <- playerStats %>%
group_by(PLAYER_ID) %>%
summarise(GAMES= mean(GAMES),
GAMES_STARTED=mean(GAMES_STARTED),
MINUTES_PLAYED = mean(MINUTES_PLAYED),
TWO_POINTS_FG = mean(TWO_POINTS_FG),
TWO_POINTS_FG_ATTEMPTS= mean(TWO_POINTS_FG_ATTEMPTS),
EFF_FIELD_GOAL_PERCENT = mean(EFF_FIELD_GOAL_PERCENT),
OFFENSIVE_REBOUNDS = mean(OFFESNIVE_REBOUNDS),
DEFENSIVE_REBOUNDS = mean(DEFENSIVE_REBOUNDS),
BLOCKS = mean(BLOCKS),
POINTS=mean(POINTS),
SALARY=mean(SALARY),
POSITION=paste(POSITION, collapse=",")) %>%
mutate(c_sg= ifelse(grepl("C-SG",POSITION, fixed=TRUE), 1, ifelse(grepl("SG", POSITION, fixed=TRUE), 1, 0))) %>%
mutate(c_sf=ifelse(grepl("C-SF",POSITION, fixed=TRUE), 1 , ifelse(grepl("SF", POSITION, fixed=TRUE), 1, 0)))%>%
mutate(c_pg=ifelse(grepl("C-PG",POSITION, fixed=TRUE), 1 , ifelse(grepl("PG", POSITION, fixed=TRUE), 1, 0)))%>%
mutate(c_pf=ifelse(grepl("C-PF",POSITION, fixed=TRUE), 1 , ifelse(grepl("PF", POSITION, fixed=TRUE), 1, 0))) %>%
select(-c(POSITION))
cAttributes <- playerStats %>%
select(-c(PLAYER_ID, c_sg, c_sf, c_pg, c_pf))
# among the attributes that are selected find the correlations between then
correlation <- rcorr(as.matrix(cAttributes))
correlationFlattened = flattenCorrelationMatrix(correlation$r, correlation$P)
corGreaterThan99 <- filter(correlationFlattened, cor>0.95)
print(corGreaterThan99)
corrplot(correlation$r, type="upper", order="hclust", tl.col="black", tl.srt=45)
vifcor(cAttributes, th=0.95)
library('RSQLite') # Loads the pacakges that is reqiured for reading from the sql database
library('dplyr') # perform operations on data frame
library('Hmisc')
library('corrplot')
library('ggplot2')
library('cluster')
library('LICORS')
library('fpc')
source('utils.R')
basketballDb <- dbConnect(SQLite(), "/Users/abhinav/Abhinav/howba/app/src/gp1/db/basketBall.db")
sqlStatement  <- "SELECT * FROM C_PREVIOUS5YEARS"
playerStats <- dbGetQuery(basketballDb, sqlStatement)
playerStats <- tbl_df(playerStats)
playerStats <- playerStats %>%
group_by(PLAYER_ID) %>%
summarise(GAMES= mean(GAMES),
GAMES_STARTED=mean(GAMES_STARTED),
MINUTES_PLAYED = mean(MINUTES_PLAYED),
TWO_POINTS_FG = mean(TWO_POINTS_FG),
TWO_POINTS_FG_ATTEMPTS= mean(TWO_POINTS_FG_ATTEMPTS),
EFF_FIELD_GOAL_PERCENT = mean(EFF_FIELD_GOAL_PERCENT),
OFFENSIVE_REBOUNDS = mean(OFFESNIVE_REBOUNDS),
DEFENSIVE_REBOUNDS = mean(DEFENSIVE_REBOUNDS),
BLOCKS = mean(BLOCKS),
POINTS=mean(POINTS),
SALARY=mean(SALARY),
POSITION=paste(POSITION, collapse=",")) %>%
mutate(c_sg= ifelse(grepl("C-SG",POSITION, fixed=TRUE), 1, ifelse(grepl("SG", POSITION, fixed=TRUE), 1, 0))) %>%
mutate(c_sf=ifelse(grepl("C-SF",POSITION, fixed=TRUE), 1 , ifelse(grepl("SF", POSITION, fixed=TRUE), 1, 0)))%>%
mutate(c_pg=ifelse(grepl("C-PG",POSITION, fixed=TRUE), 1 , ifelse(grepl("PG", POSITION, fixed=TRUE), 1, 0)))%>%
mutate(c_pf=ifelse(grepl("C-PF",POSITION, fixed=TRUE), 1 , ifelse(grepl("PF", POSITION, fixed=TRUE), 1, 0))) %>%
select(-c(POSITION))
cAttributes <- playerStats %>%
select(-c(PLAYER_ID, c_sg, c_sf, c_pg, c_pf))
# among the attributes that are selected find the correlations between then
correlation <- rcorr(as.matrix(cAttributes))
correlationFlattened = flattenCorrelationMatrix(correlation$r, correlation$P)
corGreaterThan99 <- filter(correlationFlattened, cor>0.95)
print(corGreaterThan99)
corrplot(correlation$r, type="upper", order="hclust", tl.col="black", tl.srt=45)
#from the correlation matrix we identify that the these variables be removed
# TWO_POINTS_FG_ATTEMPTS
# TWO_POINTS_FG
features <- playerStats %>%
select(-c(PLAYER_ID, TWO_POINTS_FG_ATTEMPTS, TWO_POINTS_FG, SALARY)) %>%
mutate(GAMES = (GAMES - mean(GAMES))/sd(GAMES),
GAMES_STARTED = (GAMES_STARTED - mean(GAMES_STARTED))/sd(GAMES_STARTED),
MINUTES_PLAYED= (MINUTES_PLAYED - mean(MINUTES_PLAYED)) / sd(MINUTES_PLAYED),#            #
OFFENSIVE_REBOUNDS = (OFFENSIVE_REBOUNDS -mean(OFFENSIVE_REBOUNDS)) / sd(OFFENSIVE_REBOUNDS),
DEFENSIVE_REBOUNDS = (DEFENSIVE_REBOUNDS -mean(DEFENSIVE_REBOUNDS)) / sd(DEFENSIVE_REBOUNDS),
BLOCKS = (BLOCKS -mean(BLOCKS)) / sd(BLOCKS),
POINTS = (POINTS -mean(POINTS)) / sd(POINTS)
)
plotFrame <- getPlotFrame(features)
ggplot(plotFrame, aes(x=numClusters, y=sumOfSquares)) +
geom_point() +
geom_line()
print(plotFrame)
finalNumberOfClusters = 3
km <- kmeanspp(features, k=finalNumberOfClusters, start="random", iter.max = 100, nstart = 45)
kmeans <- kmeansruns(features, krange=2:10)
bestNumberOfClusters <- kmeans$bestk
comparison <- getComparisonBetweenKmeansppAndfpc(km, kmeans)
membersOfClusters <- getMembersOfClusters(features, finalNumberOfClusters, playerStats)
mean_matrix <- getMeanMatrix(membersOfClusters)
topTwoPointScorerAttrbiutes <- getTopPlayersForAnAttribute(playerStats,finalNumberOfClusters, "TWO_POINTS_FG", membersOfClusters)
topOffensiveReboundsAttributes <- getTopPlayersForAnAttribute(playerStats,finalNumberOfClusters, "OFFENSIVE_REBOUNDS", membersOfClusters)
topDefensiveReboundsAttributes <- getTopPlayersForAnAttribute(playerStats, finalNumberOfClusters, "DEFENSIVE_REBOUNDS", membersOfClusters)
topBlocksAttributes <- getTopPlayersForAnAttribute(playerStats, finalNumberOfClusters, "BLOCKS", membersOfClusters)
bestPlayersPercentagesInEachCluster = data.frame(twoPointers= topTwoPointScorerAttrbiutes$percentages, ofrb=topOffensiveReboundsAttributes$percentages,
dfrb=topDefensiveReboundsAttributes$percentages, blocks=topBlocksAttributes$percentages)
print(bestPlayersPercentagesInEachCluster)
bestCluster <- which.max(bestPlayersPercentagesInEachCluster$dfrb)
meanSalaryBestCluster <- mean(membersOfClusters[[bestCluster]]$SALARY)
makeAnOffer <- tbl_df(membersOfClusters[[bestCluster]]) %>%
filter(DEFENSIVE_REBOUNDS > topDefensiveReboundsAttributes$score,
OFFENSIVE_REBOUNDS >  topOffensiveReboundsAttributes$score,
BLOCKS > topBlocksAttributes$score,
SALARY < meanSalaryBestCluster)
print(makeAnOffer)
library("igraph")
# Before we run anaything just clean up all the environment vaiables
# saves you a ton of time
rm(list = ls())
implicitGraphFile <- "/Users/abhinav/Abhinav/sdma/project/twe/twe/data/gml/adacos_implicit.gml"
g <- read.graph(implicitGraphFile, format = "gml")
g.comFastUnfolding <- multilevel.community(g)
g.comLouvain <- cluster_louvain(g)
g.comFastGreedy <- fastgreedy.community(g)
paste(c("The number of communities in the fast unfolding of communities", max(g.comFastUnfolding$membership)))
paste(c("The number of communities in the louvain communities", max(g.comLouvain$membership)))
paste(c("The number of communities in the fast greedy community: ", max(g.comFastGreedy$membership)))
paste(c("max modularity of fast unfolding of communities: ", max(g.comFastUnfolding$modularity)))
paste(c("max modularity of louvain community", max(g.comLouvain$modularity)))
paste(c("max modulairty of ¬the gast greedy community", max(g.comFastGreedy$modularity)))
png('greedy_community_1000_restaurants_only', width=3000, height=2000)
V(g)$color <- g.comLouvain$membership + 1
layout <- layout.sphere(g)
plot(g, vertex.label=NA, vertex.size=1)
dev.off()
library("igraph")
# Before we run anaything just clean up all the environment vaiables
# saves you a ton of time
rm(list = ls())
implicitGraphFile <- "/Users/abhinav/Abhinav/sdma/project/twe/twe/data/gml/adacos_implicit.gml"
g <- read.graph(implicitGraphFile, format = "gml")
g.comFastUnfolding <- multilevel.community(g)
g.comLouvain <- cluster_louvain(g)
g.comFastGreedy <- fastgreedy.community(g)
library("igraph")
# Before we run anaything just clean up all the environment vaiables
# saves you a ton of time
rm(list = ls())
implicitGraphFile <- "/Users/abhinav/Abhinav/sdma/project/twe/twe/data/gml/adacos_implicit.gml"
g <- read.graph(implicitGraphFile, format = "gml")
g.comFastUnfolding <- multilevel.community(g)
g.comLouvain <- cluster_louvain(g)
g.comFastGreedy <- fastgreedy.community(g)
paste(c("The number of communities in the fast unfolding of communities", max(g.comFastUnfolding$membership)))
paste(c("The number of communities in the louvain communities", max(g.comLouvain$membership)))
paste(c("The number of communities in the fast greedy community: ", max(g.comFastGreedy$membership)))
paste(c("max modularity of fast unfolding of communities: ", max(g.comFastUnfolding$modularity)))
paste(c("max modularity of louvain community", max(g.comLouvain$modularity)))
paste(c("max modulairty of ¬the gast greedy community", max(g.comFastGreedy$modularity)))
png('greedy_community_1000_restaurants_only', width=3000, height=2000)
V(g)$color <- g.comLouvain$membership + 1
layout <- layout.sphere(g)
plot(g, vertex.label=NA, vertex.size=1)
dev.off()
library("igraph")
# Before we run anaything just clean up all the environment vaiables
# saves you a ton of time
rm(list = ls())
implicitGraphFile <- "/Users/abhinav/Abhinav/sdma/project/twe/twe/data/gml/adacos_implicit.gml"
g <- read.graph(implicitGraphFile, format = "gml")
g.comFastUnfolding <- multilevel.community(g)
g.comLouvain <- cluster_louvain(g)
g.comFastGreedy <- fastgreedy.community(g)
paste(c("The number of communities in the fast unfolding of communities", max(g.comFastUnfolding$membership)))
paste(c("The number of communities in the louvain communities", max(g.comLouvain$membership)))
paste(c("The number of communities in the fast greedy community: ", max(g.comFastGreedy$membership)))
paste(c("max modularity of fast unfolding of communities: ", max(g.comFastUnfolding$modularity)))
paste(c("max modularity of louvain community", max(g.comLouvain$modularity)))
paste(c("max modulairty of ¬the gast greedy community", max(g.comFastGreedy$modularity)))
png('greedy_community_1000_restaurants_only', width=3000, height=2000)
V(g)$color <- g.comFastGreedy$membership + 1
layout <- layout.sphere(g)
plot(g, vertex.label=NA, vertex.size=1, layout=layout)
dev.off()
library("igraph")
# Before we run anaything just clean up all the environment vaiables
# saves you a ton of time
rm(list = ls())
implicitGraphFile <- "/Users/abhinav/Abhinav/sdma/project/twe/twe/data/gml/adacos_implicit.gml"
g <- read.graph(implicitGraphFile, format = "gml")
g.comFastUnfolding <- multilevel.community(g)
g.comLouvain <- cluster_louvain(g)
g.comFastGreedy <- fastgreedy.community(g)
paste(c("The number of communities in the fast unfolding of communities", max(g.comFastUnfolding$membership)))
paste(c("The number of communities in the louvain communities", max(g.comLouvain$membership)))
paste(c("The number of communities in the fast greedy community: ", max(g.comFastGreedy$membership)))
paste(c("max modularity of fast unfolding of communities: ", max(g.comFastUnfolding$modularity)))
paste(c("max modularity of louvain community", max(g.comLouvain$modularity)))
paste(c("max modulairty of ??the gast greedy community", max(g.comFastGreedy$modularity)))
png('greedy_community_1000_restaurants_only', width=3000, height=2000)
V(g)$color <- g.comFastGreedy$membership + 1
layout <- layout.sphere(g)
plot(g, vertex.label=NA, vertex.size=1, layout=layout)
dev.off()
##################################################################
# Load the required libraries
##################################################################
library('dplyr')
library('data.table')
library("lubridate")
##################################################################
# Cleaning up environment variables if any
##################################################################
rm(list=ls())
##################################################################
# Loading the csv data file into the memory
##################################################################
csvFile <- "../data/20150325.csv"
data <- tbl_df(fread(csvFile))
##################################################################
# EXPLORATORY ANALYSIS
##################################################################
# FOR EVERY HOUR FIND THE AVERAGE TIPPING IN NYC
data <- data %>%
mutate(pickup_time=ymd_hms(pickup_time),
dropoff_time=ymd_hms(dropoff_time),
pickup_hour = hour(pickup_time),
pickup_minutes = minute(pickup_time),
pickup_seconds = seconds(pickup_time),
dropoff_hour = hour(dropoff_time),
dropoff_minutes = minute(dropoff_time),
dropoff_seconds = second(dropoff_time)
) %>%
arrange(pickup_hour, pickup_minutes, pickup_seconds)
groupedByHour <- data %>%
group_by(pickup_hour, pickup_minutes) %>%
summarise(averageTip=mean(tip),
averageTotal= mean(total))
#####################################################################
#getting all the data in the blast hour
#####################################################################
aroundTheBlast <- data %>%
filter(pickup_hour==15)
write.csv(aroundTheBlast, '../data/aroundTheBlast.csv')
setwd("~/Abhinav/howba/project/src")
##################################################################
# Load the required libraries
##################################################################
library('dplyr')
library('data.table')
library("lubridate")
##################################################################
# Cleaning up environment variables if any
##################################################################
rm(list=ls())
##################################################################
# Loading the csv data file into the memory
##################################################################
csvFile <- "../data/20150325.csv"
data <- tbl_df(fread(csvFile))
##################################################################
# EXPLORATORY ANALYSIS
##################################################################
# FOR EVERY HOUR FIND THE AVERAGE TIPPING IN NYC
data <- data %>%
mutate(pickup_time=ymd_hms(pickup_time),
dropoff_time=ymd_hms(dropoff_time),
pickup_hour = hour(pickup_time),
pickup_minutes = minute(pickup_time),
pickup_seconds = seconds(pickup_time),
dropoff_hour = hour(dropoff_time),
dropoff_minutes = minute(dropoff_time),
dropoff_seconds = second(dropoff_time)
) %>%
arrange(pickup_hour, pickup_minutes, pickup_seconds)
groupedByHour <- data %>%
group_by(pickup_hour, pickup_minutes) %>%
summarise(averageTip=mean(tip),
averageTotal= mean(total))
#####################################################################
#getting all the data in the blast hour
#####################################################################
aroundTheBlast <- data %>%
filter(pickup_hour==15)
write.csv(aroundTheBlast, '../data/aroundTheBlast.csv')
View(aroundTheBlast)
View(aroundTheBlast)
